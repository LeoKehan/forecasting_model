{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "C extension: DLL load failed: 找不到指定的模块。 not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\python2.7\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     25\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 26\u001b[1;33m     from pandas._libs import (hashtable as _hashtable,\n\u001b[0m\u001b[0;32m     27\u001b[0m                              \u001b[0mlib\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0m_lib\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python2.7\\lib\\site-packages\\pandas\\_libs\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mtslib\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0miNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNaT\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimestamp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mTimedelta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mOutOfBoundsDatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: DLL load failed: 找不到指定的模块。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-0370abee5486>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstride_tricks\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mas_strided\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mload_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\python2.7\\lib\\site-packages\\pandas\\__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m                       \u001b[1;34m\"pandas from the source directory, you may need to run \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m                       \u001b[1;34m\"'python setup.py build_ext --inplace --force' to build \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 35\u001b[1;33m                       \"the C extensions first.\".format(module))\n\u001b[0m\u001b[0;32m     36\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     37\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mdatetime\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: C extension: DLL load failed: 找不到指定的模块。 not built. If you want to import pandas from the source directory, you may need to run 'python setup.py build_ext --inplace --force' to build the C extensions first."
     ]
    }
   ],
   "source": [
    "import abc  # abstract base class\n",
    "import os.path\n",
    "import sys\n",
    "import datetime as dt\n",
    "import numpy as np\n",
    "from numpy.lib.stride_tricks import as_strided\n",
    "import pandas as pd\n",
    "import math\n",
    "from keras.models import Sequential, load_model\n",
    "from keras.models import Model as Functional_model\n",
    "from keras.layers import Dense, Dropout, Convolution1D, Flatten, Input, merge, Activation\n",
    "from keras.optimizers import SGD\n",
    "from keras.callbacks import CSVLogger, EarlyStopping\n",
    "import tensorflow as tf\n",
    "from keras import backend as K\n",
    "from keras import metrics\n",
    "import utils.utils as utils\n",
    "import config as config\n",
    "from keras.layers import LSTM\n",
    "from ann_forecast.ann_abstr import Ann_model\n",
    "from metrics import mean_neg_log_loss_parametric, mean_neg_log_loss_discrete\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Ann_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-2-f8a808ddc475>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mclass\u001b[0m \u001b[0mProb_LSTM\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mAnn_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m     \"\"\"\n\u001b[0;32m      3\u001b[0m     \u001b[0mLSTM\u001b[0m \u001b[0mneural\u001b[0m \u001b[0mnetwork\u001b[0m \u001b[0mdefinition\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m     \u001b[0mImplementation\u001b[0m \u001b[1;32mwith\u001b[0m \u001b[0mSoftmax\u001b[0m \u001b[0mDistribution\u001b[0m \u001b[0mNetwork\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \"\"\"\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Ann_model' is not defined"
     ]
    }
   ],
   "source": [
    "class Prob_LSTM(Ann_model):\n",
    "    \"\"\"\n",
    "    LSTM neural network definition\n",
    "    Implementation with Softmax Distribution Network\n",
    "    \"\"\"\n",
    "    prefix = 'lstm_'\n",
    "    def __init__(self,\n",
    "                 model_identifier,\n",
    "                 granularity_s,\n",
    "                 forecast_horizon_mins,\n",
    "                 look_back_mins,\n",
    "                 hidden_neurons,\n",
    "                 working_directory=config.working_directory,\n",
    "                 trained_models_folder=config.trained_models_folder,\n",
    "                 dropout=0,\n",
    "                 forecast_type='watthours',\n",
    "                 learning_rate=0.1,\n",
    "                 use_cal_vars=False,\n",
    "                 activation='sigmoid',\n",
    "                 pdf_sample_points_min=0.0,\n",
    "                 pdf_sample_points_max=7000.0,\n",
    "                 pdf_resolution=200.0):\n",
    "        \"\"\" init general attributes required for Ann_model \"\"\"\n",
    "        self.model_identifier = model_identifier\n",
    "        self.granularity_s = granularity_s\n",
    "        self.forecast_horizon_mins = forecast_horizon_mins\n",
    "        self.look_back_mins = look_back_mins\n",
    "        self.hidden_neurons = hidden_neurons\n",
    "        self.working_directory = working_directory\n",
    "        self.trained_models_folder = trained_models_folder\n",
    "        self.dropout = dropout\n",
    "        self.forecast_type = forecast_type\n",
    "        self.learning_rate = learning_rate\n",
    "        self.use_cal_vars = use_cal_vars\n",
    "        self.activation = activation\n",
    "        self.loss_func = mean_neg_log_loss_discrete  # 'categorical_crossentropy' #\n",
    "        \"\"\" init model-specific attributes \"\"\"\n",
    "        self.pdf_sample_points_min = pdf_sample_points_min\n",
    "        self.pdf_sample_points_max = pdf_sample_points_max\n",
    "        self.pdf_resolution = pdf_resolution\n",
    "        self.pdf_granularity = (pdf_sample_points_max - pdf_sample_points_min) / pdf_resolution\n",
    "        self.pdf_sample_points = np.linspace(pdf_sample_points_min, pdf_sample_points_max, pdf_resolution)\n",
    "        self.init_model()\n",
    "\n",
    "    \"\"\"\timplement abstract methods \"\"\"\n",
    "\n",
    "    def generate_model(self):\n",
    "        \"\"\"\n",
    "        Generate the neural network model\n",
    "        Define the model's architecture and the implemented functions\n",
    "        \"\"\"\n",
    "        # Size of input layer\n",
    "        # -------------------\n",
    "        # LSTMs expect a 3-dim input of the form [samples, timesteps, features]\n",
    "        if self.use_cal_vars:\n",
    "            input_layer = Input(shape=(self.nb_input_neurons, 5))\n",
    "        else:\n",
    "            input_layer = Input(shape=(self.nb_input_neurons, 1))\n",
    "        # input_layer = Input(shape=(1, self.nb_input_neurons)) # TODO Dimension???!!\n",
    "\n",
    "        # Number of hidden layers\n",
    "        nb_layers = np.array(self.hidden_neurons).shape[0]\n",
    "        if nb_layers > 1:\n",
    "            x = LSTM(self.hidden_neurons[0], return_sequences=True)(input_layer)\n",
    "            x = Dropout(self.dropout)(x) # dropout layer to prevent overfitting\n",
    "        else:\n",
    "            x = LSTM(self.hidden_neurons[0])(input_layer)\n",
    "            x = Dropout(self.dropout)(x)\n",
    "        iter_temp = 1\n",
    "        for hn in self.hidden_neurons[1:]:\n",
    "            if iter_temp == len(self.hidden_neurons) - 1:\n",
    "                x = LSTM(hn)(x)\n",
    "            else:\n",
    "                # if some hidden layers have to be added return sequence\n",
    "                x = LSTM(hn, return_sequences=True)(x)\n",
    "            iter_temp = iter_temp + 1\n",
    "            x = Dropout(self.dropout)(x)\n",
    "\n",
    "        # Output layer is a pdf function with all power \"bins\", see theory\n",
    "        pdf = Dense(len(self.pdf_sample_points), activation='softmax')(x)  # previous layers (x) are stacked\n",
    "        model = Functional_model(input=input_layer, output=pdf) # LSTM model definition\n",
    "        return model\n",
    "\n",
    "    def write_training_log(self, history):\n",
    "        \"\"\"\n",
    "        Write file with training's results\n",
    "        \"\"\"\n",
    "        with open(os.path.join(self.working_directory, 'training_log.csv'), 'a') as log_file:\n",
    "            log_file.write(self.model_name + ',' + \\\n",
    "                           str(self.model_identifier) + ',' + \\\n",
    "                           str(self.granularity_s) + ',' + \\\n",
    "                           str(self.forecast_horizon_mins) + ',' + \\\n",
    "                           str(self.look_back_mins) + ',' + \\\n",
    "                           str(self.hidden_neurons) + ',' + \\\n",
    "                           str(self.forecast_type) + ',' + \\\n",
    "                           str(history.history['loss'][-1]) + ',' + \\\n",
    "                           str(history.history['val_loss'][-1]) + '\\n')\n",
    "\n",
    "    def generate_input_data(self, lagged_vals, t0):\n",
    "        \"\"\"\n",
    "        Prepare (normalize) input data for forecasting\n",
    "        \"\"\"\n",
    "        X = self.scale(lagged_vals)\n",
    "\n",
    "        X = X.reshape((X.shape[0], X.shape[1], 1))\n",
    "\n",
    "        if self.use_cal_vars:\n",
    "\n",
    "            minutes = t0.minute\n",
    "            # Normalized values\n",
    "            minutes = minutes / 60.0\n",
    "            hours = t0.hour\n",
    "            hours = hours / 24.0\n",
    "            day = t0.weekday\n",
    "            day = day / 7.0\n",
    "            month = t0.month\n",
    "            month = month / 12.0\n",
    "\n",
    "            minsaux = np.zeros(X.shape)\n",
    "            hoursaux = np.zeros(X.shape)\n",
    "            daysaux = np.zeros(X.shape)\n",
    "            monthsaux = np.zeros(X.shape)\n",
    "\n",
    "            for i_sample in range(len(t0)):\n",
    "                for i_timestamp in range(lagged_vals.shape[1]):\n",
    "                    minsaux[i_sample][i_timestamp][0] = minutes[i_sample]\n",
    "                    hoursaux[i_sample][i_timestamp][0] = (hours[i_sample])\n",
    "                    daysaux[i_sample][i_timestamp][0] = (day[i_sample])\n",
    "                    monthsaux[i_sample][i_timestamp][0] = (month[i_sample])\n",
    "\n",
    "            minutes = minsaux\n",
    "            hours = hoursaux\n",
    "            day = daysaux\n",
    "            month = monthsaux\n",
    "\n",
    "            if self.activation == 'tanh':\n",
    "                minutes = minutes * 2.0 - 1  # scale to [-1,1]\n",
    "                hours = hours * 2.0 - 1\n",
    "                day = day * 2.0 - 1\n",
    "                month = month * 2.0 - 1\n",
    "\n",
    "            X = np.concatenate((X, minutes, hours, day, month), axis=2)\n",
    "\n",
    "        return X\n",
    "\n",
    "    def generate_output_data(self, ground_truth):\n",
    "        \"\"\"\n",
    "        Generates an output of type [0,0,...,Pt,...,0,0] to be compared against the pdf output from the model\n",
    "        \"\"\"\n",
    "        nb_sample_points = len(self.pdf_sample_points)\n",
    "        batch_size = len(ground_truth)\n",
    "        y = np.zeros((batch_size, nb_sample_points))\n",
    "\n",
    "        pdf_sample_points_grid = self.pdf_sample_points.reshape((1, nb_sample_points))\n",
    "        pdf_sample_points_grid = np.repeat(pdf_sample_points_grid, batch_size, axis=0)\n",
    "\n",
    "        ground_truth_grid = ground_truth.reshape((batch_size, 1))\n",
    "        ground_truth_grid = np.repeat(ground_truth_grid, nb_sample_points, axis=1)\n",
    "\n",
    "        rows_idx = np.arange(0, batch_size)\n",
    "        cols_idx = np.argmin(np.abs(pdf_sample_points_grid - ground_truth_grid), axis=1)\n",
    "        y[rows_idx, cols_idx] = 1.0\n",
    "\n",
    "        return y\n",
    "\n",
    "    def predict_on_preprocessed_input(self, X):\n",
    "        \"\"\"\n",
    "        Employ model to predict X values\n",
    "        \"\"\"\n",
    "        if X.shape[1] != self.nb_input_neurons:\n",
    "            print(dt.datetime.now().strftime('%x %X') + ' Dim 1 of X does not match number of input neuros.')\n",
    "            return\n",
    "\n",
    "        y_pred = self.model.predict(X) / self.pdf_granularity\n",
    "\n",
    "        batch_size = y_pred.shape[0]\n",
    "        nb_sample_points = len(self.pdf_sample_points)\n",
    "        pdf_sp_grid = np.repeat(self.pdf_sample_points.reshape((1, nb_sample_points)), batch_size, axis=0)\n",
    "        return (pdf_sp_grid, y_pred)\n",
    "\n",
    "\n",
    "    def generate_model_name(self):\n",
    "        \"\"\"\n",
    "        Generate the model's file name with its main characteristics\n",
    "        \"\"\"\n",
    "        name = self.prefix + str(self.model_identifier) + \\\n",
    "               '_' + str(self.forecast_type) + \\\n",
    "               '_granu' + str(self.granularity_s) + \\\n",
    "               '_hor' + str(self.forecast_horizon_mins) + \\\n",
    "               '_lb' + str(self.look_back_mins) + \\\n",
    "               '_drop' + str(self.dropout) + \\\n",
    "               '_pdflen' + str(len(self.pdf_sample_points)) + \\\n",
    "               '_' + self.activation\n",
    "        if self.use_cal_vars:\n",
    "            name += '_cal'\n",
    "\n",
    "        name += '_lay'\n",
    "        for hn in self.hidden_neurons:\n",
    "            name = name + str(hn) + '-'\n",
    "        name = name[:-1]\n",
    "        return name[:249]  # limit length of name for ntfs file system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
